---
title: "Annotation goes distributional:"
subtitle: "Modeling semantic predictors of the dative alternation using vector space models"
author:
  - Chiara Paolini
  - Benedikt Szmrecsanyi
  - Mariana Montes
format:
  revealjs:
    footer: "Taal en Tongval Colloquium - Gent, 2022-11-18"
execute:
  echo: false
---

```{r}
#| label: setup
#| include: false
headings <- c("Introduction: the dative alternation",
              "From vectors to predictors",
              "Forests and clouds",
              "Conclusions")
source(here::here("Taal_tongval", "R", "plots.R"))
read_data <- function(fname) {
  read_tsv(here::here("Taal_tongval", "data_processed", paste0(fname, ".tsv")), show_col_types = FALSE)
}
recipient_coords <- read_data("recipient_coords")
theme_coords <- read_data("theme_coords")
tokens <- read_data("dat_clusters")
varimp_bin <- read_data("varimp_bin")
varimp_full <- read_data("varimp_full") %>% filter(Varimp > 0)
```

## Outline

```{r}
#| label: outline
#| results: asis
for (heading in headings) {
  cat("-", heading, "\n")
}
i <- 1
```

::: notes
In this talk, I would like to introduce you to the first case study of my PhD research project called "How much does meaning matter? A fresh look at grammatical alternations". The goal of this research is to examine if and how the way people choose between different ways of saying the same thing (i.e., grammatical alternations) depends on the meaning of the words in the utterance. I will start by introduce you to the dative alternation, our case study, and how lexical semantics is traditionally modeled in variationist linguistics. Then, I will illustrate our proposal, namely automatically-generated semantic predictors using DS techniques, and finally I will discuss the analyses and the results obtained from our first case study using type-level distributional semantic predictors.
:::

# `r headings[[i]]`

## The dative alternation

::: {style="color: #F39D41;"}
**(1) a. Ditransitive** dative variant
:::

    \[*The waiter*\]~subject~ \[*gave*\]~verb~ \[*my cousin*\]~recipient~     \[*some pizza*\]~theme~

::: {style="color: #F39D41;"}
   **b. Prepositional** dative variant
:::

    \[*The waiter*\]~subject~ \[*gave*\]~verb~ \[*some pizza*\]~theme~     \[*to my cousin*\]~recipient~

::: notes
Let's dive into our case study. The DA is one of the most investigated cases of grammatical alternation - where we define a GA as "two or more constructions, called variants, with a highly similar meaning. An A represents choice point for the individual speaker".

In English, there are two ways, two variants to encode the dative relation: the ditransitive dative construction (recipient-theme order), and the prepositional dative construction (theme-recipient order).
:::

## Modelling grammatical alternations

In previous literature, focus on three kinds of predictors:

1.  **Formal predictors:** e.g., *structural complexity of constituents* (e.g., presence of heavy postmodification), *pronominality*, and *constituent length* (in words, syllables, or similar)

2.  **Information status‐related predictors:** e.g., *givenness*

3.  **Semantic, coarse-grained, higher-level predictors:** e.g., *animacy* (i.e., annotate for a binary distinction between animate and inanimate recipients -- see Bresnan et al. 2007)

```{r}
#serve a far cambiare l'indice al ciclo degli headings
#| label: add-heading1
#| include: false
i <- i+1
```

::: notes
To explore the correlation of choices between the two variants both language-internal predictors as well as language-external predictors (such as sex, race/ethnicity, etc) are implemented. Regarding the internal predictors, the traditional variationist approach is fairly good at manually annotating for formal, top-down predictors, such as in (1) and (2) for the dative alternation, but when it comes to the third point, namely the semantic predictors, the VA would annotate only for few semantic factors such as animacy, which can be defined as a top-down notion. This is because (next slide)
:::

## Role of semantic predictors in alternation predictions

**Annotating for semantics is labor‐intensive and challenging to perform objectively.**

::: {.caption style="font-size: 0.7em; text-align: center;"}
*What role do semantic characteristics play in the choice of one of the two variants?*

*At the current state of the research, we know very little about them.*
:::

::: {style="text-align: center; color: #E04836;"}
**We assume broad semantic equivalence of dative variants, but we are interested in extent to which semantics of materials in argument slots predicts choice.**
:::

::: notes
Annotating for semantics is labor‐intensive and time-consuming, and it's challenging to perform objectively and systematically. So if we ask ourselves: What role do semantic characteristics play in the choice of one of the two variants? We do not have a clear answer because we are missing those data. And this is the research gap we want to cover.

In particular, we are interested how much the semantic characteristics of the lexical material in the slots of the dative variants predict the choice.
:::

# `r headings[[i]]`

## Automatically-generated semantic predictors

::: {style="text-align: center; color: #E04836;"}
**We use automatically-generated, corpus-based semantic predictors using distributional semantic models (DSMs).**
:::

::: {style="font-size: 0.7em;"}
-   New inputs from DMSs: **more data, less annotation**

-   Distributional semantics is an usage-based model of meaning, based on the assumption that items that occur in similar contexts in a given corpus will be semantically similar, while those that occur in different contexts will be semantically different.(Lenci 2018)
:::

::: notes
What we propose is a completely bottom-up approach to annotation by using .... predictors.

DSMs can help us understanding and bring to the light the semantic characteristics of the lexical context in which those variants are embedded. In a nutshell, DS is a usage-based model of meaning, based on the assumption that items that occur in similar contexts in a given corpus will be semantically similar, while those that occur in different contexts will be semantically different. To do that, we operationalize the differences in the distribution of two (or more) items by extracting their co-occurrences from a corpus: those differences can tell us something about the semantic relatedness of items.
:::

## Examples: recipient type-lemmas

::: {style="color: #F39D41;"}
**(2) a. DAT-4100**
:::

::: {style="font-size: 0.8em;"}
     \[*if I*\]~subject~ \[*gave*\]~verb~ \[*it*\]~theme~ \[*to the government*\]~recipient~      they would just waste it.
:::

::: {style="color: #F39D41;"}
   **b. DAT-4067**
:::

::: {style="font-size: 0.8em;"}
     \[*The judge*\]~subject~ \[*will usually, uh, give*\]~verb~ \[*custody*\]~theme~      \[*to the mother*\]~recipient~ ninety-seven percent of the time.
:::

::: notes
But, what does it mean annotating predictors with DS? What we are going to distributionally model are the recipient and the theme of the alternation, here exemplified in two observations form our dataset. (read the examples).
:::

## Matrix of recipients

+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+
|                                                | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} |
|                                                | daughter/nn                                    | europe/np                                      | it/pp                                          | dad/nn                                         | troop/nn                                       |
|                                                | :::                                            | :::                                            | :::                                            | :::                                            | :::                                            |
+================================================+================================================+================================================+================================================+================================================+================================================+
| ::: {style="color: #F39D41; font-size: 35px;"} | 1                                              | 16                                             | 3                                              | 0                                              | 10                                             |
| **government/nn**                              |                                                |                                                |                                                |                                                |                                                |
| :::                                            |                                                |                                                |                                                |                                                |                                                |
+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+
| ::: {style="color: #F39D41; font-size: 35px;"} | 21                                             | 0                                              | 5                                              | 12                                             | 0                                              |
| **mother/nn**                                  |                                                |                                                |                                                |                                                |                                                |
| :::                                            |                                                |                                                |                                                |                                                |                                                |
+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+
| ::: {style="color: #F39D41; font-size: 35px;"} | 0                                              | 1                                              | 0                                              | 0                                              | 5                                              |
| **advance/nn**                                 |                                                |                                                |                                                |                                                |                                                |
| :::                                            |                                                |                                                |                                                |                                                |                                                |
+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+

::: {style="font-size: 0.7em;"}
-   ***Dative alternation dataset from Szmrecsanyi et al. (2017)***, which covers **N = 1,190** dative observations in contemporary **spoken American English** (Switchboard corpus)
-   Corpus for building DMSs: ***Corpus of Contemporary American English** (COCA),* spoken register (ca. **127 million** tokens)
:::

::: notes
In this first part of the study, we implemented what we call a **type-level model**. -\> what is a type?

Let's consider only the group of recipients, here exemplified by the types government/nn and mother/nn. As you can see in this co-occurence matrix, each row represents a target-word (from the dtasate) from the recipient slot, while each column represents a context word (from the corpus, with which we train the model): the aggregation of the frequencies between the single TW and all the CW constitutes a **word-type vector,** that is a distributional representation of a recipient lemma in that specific corpus. What you see here are raw frequencies, that is how many time the TW co-occur with the CW \[example with gov\]. However, -\>
:::

## Matrix of recipients - PPMI

+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+
|                                                | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} | ::: {style="color: #8D5924; font-size: 35px;"} |
|                                                | daughter/nn                                    | europe/np                                      | it/pp                                          | dad/nn                                         | troop/nn                                       |
|                                                | :::                                            | :::                                            | :::                                            | :::                                            | :::                                            |
+================================================+================================================+================================================+================================================+================================================+================================================+
| ::: {style="color: #F39D41; font-size: 35px;"} | 0                                              | 3.23                                           | 0.21                                           | 0                                              | 2.59                                           |
| **government/nn**                              |                                                |                                                |                                                |                                                |                                                |
| :::                                            |                                                |                                                |                                                |                                                |                                                |
+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+
| ::: {style="color: #F39D41; font-size: 35px;"} | 4.36                                           | 0                                              | 1.65                                           | 2.89                                           | 0                                              |
| **mother/nn**                                  |                                                |                                                |                                                |                                                |                                                |
| :::                                            |                                                |                                                |                                                |                                                |                                                |
+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+
| ::: {style="color: #F39D41; font-size: 35px;"} | 0                                              | 2.09                                           | 0                                              | 0                                              | 3.67                                           |
| **advance/nn**                                 |                                                |                                                |                                                |                                                |                                                |
| :::                                            |                                                |                                                |                                                |                                                |                                                |
+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+------------------------------------------------+

::: {style="font-size: 0.6em;"}
-   **Pointwise Mutual Information (PMI):** the (log) probability of co-occurrence scaled by the product of the single probability of occurrence. In a nutshell, we want to quantify the likelihood of co-occurrence of two words if the two of them were independent.
-   **Positive Pointwise mutual information (PPMI):** Based on the same principle of the PMI, the negative values are replaced by 0 to better manage the possible inaccuracies that come from them.
:::

::: notes
Raw frequencies are transformed, or better, weighted using **association strength measures, such as PMI or PPMI**, that allow the model to bring up to the light the informative semantic relationships between the words.

iIn other words, the values here represent the the attraction, or the association strength between the target word and a context word.

It is important to acknowledge that building a DS model means training a DS model workflow, a type-level one in this case, with different parameters and compare them to pick the best one BASED ON CUSTOMARY CRITERIA.

There is a third matrix, namely distance matrix, computed to represent the distributional distance between the lemmas.
:::

```{r}
#| label: add-heading2
#| include: false
i <- i+1
```

# `r headings[[i]]`

## Clouds of recipients

```{r}
#| label: fig-tsne-r
#| fig-cap: Scatterplot of recipient lemmas. Colors are clusters, labelled by their central members.
tsne_plot(recipient_coords) %>%
  add_point(recipient_coords %>% filter(cw == "government/nn"), -6, 0, font_size = 15) %>%
  add_point(recipient_coords %>% filter(cw == "mother/nn"), -7, font_size = 15)
```

::: notes
Going back to our question, what does it mean building the semantic predictors using DS?, it means clustering the type-word vectors, that is our recipient lemmas in this case, by first identifying the central member of the cluster (called medoid) from the data, and then grouping the type-word vectors around them based on Euclidean distance metric. We provide the number of clusters the algorithm should create: 3, 8, or 15 like in our case.

Here, a nice plot of the clusters, or clouds as Mariana Montes says, of the recipients in our best model. (The best model is CS_4\_ol_10000_ppmi_10_cosine_k15 (with dimensionality reduction)).

(describe the clusters)
:::

## Clouds of themes

```{r}
#| label: fig-tsne-t
#| fig-cap: Scatterplot of themes lemmas. Colors are clusters, labelled by their central members.
tsne_plot(theme_coords) %>%
  add_point(theme_coords %>% filter(cw == "it/pp"), -7, -10, vjust = 1, font_size = 15)
```

## From clouds to distributional semantic predictors

::: {style="text-align: center; color: #E04836;"}
Each grouping of recipient/theme lemmas represents what we call ***distributional (semantic) predictor.***
:::

::: {style="text-align: center;"}
The prediction of the dative variants is based on the **membership of the recipient/theme type-lemma in a particular semantic cluster.**
:::

::: notes
To summarize, each grouping of recipient/theme lemmas represents what we call ***distributional (semantic) predictor.*** In what follows, we will use two of the most classic variationist statistical tools of analysis, Conditional Random forest and Regression analysis, to predict dative choices based on the membership of the recipients/themes in a particular distributional cluster.
:::

## Random forest

::: {style="font-size: 0.6em;"}
**Random forest of traditional and distributional predictors**
:::

```{r}
#| label: rf-full
varimp_dotplot(varimp_full)
```

::: notes
CRF is a multivariate statistical method that can answer to the research question: which linguistic factors help to predict the use of particular linguistic variants? (explain the forest and show immediately the next slide) - Do not insist too much on the pronominality
:::

## Inside the most important clouds

::: {style="color: #F39D41;"}
**Theme.one:**
:::

::: {style="font-size: 0.7em;"}
-   **one/pn**, everything/pn, feel/nn, it/pp, lot/rr, one/nn, poke/nn, something/pn, stuff/nn, tempt/vv, that/dd, them/pp, thing/nn, try/nn, way/nn
:::

::: {style="color: #F39D41;"}
**Recipient.everybody:**
:::

::: {style="font-size: 0.7em;"}
-   **everybody/pn**, anybody/pn, anyone/pn, anything/pn, everyone/pn, her/pp, him/pp, me/nn, me/pp, myself/pp, somebody/pn, stomach/nn, them/pp, us/pp, you/pp
:::

::: {style="color: #F39D41;"}
**Recipient.it:**
:::

::: {style="font-size: 0.7em;"}
-   **it/pp**, that/dd, theory/nn, thing/nn
:::

## Another look at the clouds: regression modelling

::: {style="font-size: 0.7em;"}
**c-values of regression model with only traditional and traditional+semantic predictors**

::: {style="font-size: 0.7em; text-align: center; color: #E04836;"}
**Index of concordance (c-value)** = non-parametric measure of how well a statistical model fits a set of observations.
:::
:::

|                                          | RM only trad predictors | RM trad+sem predictors |
|------------------------------------------|-------------------------|------------------------|
| **C-value for fixed effects**            | 0.984                   | 0.975                  |
| **C-value for fixed and random effects** | 0.985                   | 0.993                  |

::: notes
We also analyzed the distributional predictors using RM, adding them to the traditional, manually annotated, predictors. We are going to have a quick glance at the main results.

We computed the **Concordance index C: goodness of fit** (read the slide) for the two models with fixed and random effects: even if the model with T+S performs better with the mixed effects, the higher c-v of 0.98 by the T-model suggests how the traditional p performs better alone, than in combination with the semantic ones.
:::

```{r}
#| label: add-heading3
#| include: false
i <- i+1
```

# `r headings[[i]]`

## Take-home messages

::: {style="text-align: center; color: #E04836;"}
*"You shall choose a variant by the company it keeps!"*

*(semi-cit. Firth 1955)*
:::

1.  Overall, there are some **distributional semantics clusters** that are **very predictive** of the alternation

2.  Statistical analyses show how **traditional predictors outperform distributional semantics predictors** in terms of model performances

::: notes
2.  based on the c-value
:::

## Directions for future research

-   **Other alternations:**
    -   *Clausal complementation alternation* in the history of English

    -   *Progressive alternation* in Italian
-   **Experiment with token-level modeling**
    -   see Montes (2021)

::: notes
Token-level: in-depth analysis of the correlation of the single occurrences of the lemmas with the context
:::

## Thoughts? Comments? Suggestions?

![](images/thank_you.png){fig-align="center" width="677"}

::: {style="text-align: center; font-size: 0.6em;"}
***chiara.paolini\@kuleuven.be***
:::

## Parameters of the type-level models {visibility="uncounted"}

::: {style="font-size: 0.7em;"}
-   Corpus filters: **window size** (3, 4, 7), **sentence boundaries** (y/n)
-   Collocation matrix filters: **selection of context words** (dimensionality: 5000, 10000, 50000), **vocabulary filtering** (e.g., PoS, lemma, stop-words)
-   Association measures: **PPMI, log likelihood**
-   Distance measures: **Cosine**
-   Dimensionality reduction: **Euclidian + UMAP** (none, 2, 10)
-   **K-medoids (PAM)**: 3, 8, 15
:::

## Traditional predictors {visibility="uncounted"}

::: {style="font-size: 0.7em;"}
-   **Recipient/Theme.type:** The annotation distinguishes between the following categories: (1) noun phrase; (2) personal pronoun; (3) demonstrative pronoun; (4) impersonal pronoun.

-   **Recipient/Theme.definiteness:** The annotation distinguishes between the following categories: (1) definite; (2) indefinite (3) definite proper noun.

-   **Recipient/Theme.animacy:** The annotation distinguishes between the following categories: (1) human and animal; (2) collective; (3) temporal; (4) locative; (5) inanimate.

-   **Length.difference:** The log difference between recipient and theme lengths (see Bresnan & Ford 2010).

-   **Semantics (of dative verb):** (1) transfer; (2) communication; (3) abstract.

-   **Recipient/Theme.head:** Head lexeme of both the theme and the recipient.
:::

## Inside the recipient clouds {visibility="uncounted"}

::: {style="font-size: 0.6em;"}
-   **Recipient.advance**: advance/vv, america/np, arm/nn, country/nn, europe/np, government/nn, iranian/nn, nation/nn, nicaragua/np, russia/np, schwartzkopf/np, troop/nn, vietnamese/np

-   **Recipient.wife**: actress/nn, wife/nn, artist/nn, boss/nn, brother/nn, daughters/nn, friend/nn, husband/nn, kitty/np, ryan/np, sister/nn, thomases/np, trek/np

-   **Recipient.kids:** agencies/nn, boys/nn, businesses/nn, companies/nn, countries/nn, criminals/nn, dogs/nn, employees/nn, friends/nn, grandparents/nn, guys/nn, horses/nn, houses/nn, kids/nn, members/nn, parents/nn, rashad/np, sons/nn, students/nn, things/nn, twins/nn, women/nn

-   **Recipient.people:** people/nn, citizen/nn, folk/nn, individual/nn, other/nn, peasant/nn, public/nn, reader/nn, white/nn

-   **Recipient.person:** person/nn, convict/nn. criminal/nn, guy/nn, man/nn, someone/pn, stranger/nn

-   **Recipient.cour**t: court/nn, judge/nn, jury/nn, matter/nn, plaintiff/nn, topic/nn

-   **Recipient.business:** business/nn, car/nn, charity/nn, company/nn, competitor/nn, employee/nn, enterprise/nn, environment/nn, food/nn, grower/nn, household/nn, management/nn, taxpayer/nn
:::

## Inside the theme clouds #1 {visibility="uncounted"}

::: {style="font-size: 0.5em;"}
-   **Theme.discount:** discount/nn, allowance/nn, amount/nn, bargain/nn, benefit/nn, bill/nn, billion/nn, bond/nn, bonus/nn, buck/nn, budget/nn, card/nn, cash/nn, cent/nn, checkbook/nn, contract/nn, credit-card/nn, credit/nn, cut/nn, deal/nn, degree/nn, discount/nn, dollar/nn, estimate/nn, extra/nn, incentive/nn, income/nn, insurance/nn, less/da, limit/nn, loan/nn, mail/nn, million/nn, minimum/nn, money/nn, more/da, mortgage/nn, much/da, nickel/nn, number/nn, offer/nn, outlook/nn, pay/nn, paycheck/nn, payment/nn, penny/nn, percent/nn, physical/nn, point/nn, price/nn, profit-sharing/nn, raise/nn, rate/nn, rating/nn, rebate/nn, refund/nn, salary/nn, scale/nn, stipend/nn, stock/nn, tariff/nn, tax-credit/nn, tax/nn, thumbs-down/nn, ticket/nn, tune-up/nn, veto/nn, warranty/nn, worth/nn

-   **Theme.book:** book/nn, address/nn, appearance/nn, assistant/nn, band/nn, booklet/nn, book/nn, break/nn, broadcast/nn, cable/nn, call/nn, comedy/nn, demo/nn, description/nn, entertainment/nn, f/np, figure/nn, game/nn, glimpse/nn, graph/nn, headline/nn, history/nn, husband/nn, list/nn, literature/nn, look/nn, magazine/nn, meeting/nn, message/nn, music/nn, name/nn, new/jj, news/nn, newspaper/nn, novel/nn, paper/nn, picture/nn, present/nn, rap/nn, report/nn, run/nn, rush/nn, screen/nn, sermon/nn, song/nn, speech/nn, story/nn, subscription/nn, subtitle/nn, synopsis/nn, talk/nn, tape/nn, television/nn, this/dd, tile/nn, topic/nn, trip/nn, tv/nn, update/nn, warning/nn, world/nn

-   **Theme.bag:** bag/nn, amp/nn, arm/nn, azalea/nn, backpack/nn, ball/nn, bath/nn, bedroom/nn, bike/nn, bin/nn, body/nn, bulb/nn, can/nn, car/nn, coat/nn, deer/nn, dog/nn, glass/nn, gun/nn, inn/nn, junkyard/nn, knife/nn, light/nn, paint/nn, pair/nn, parking/nn, pt/nn, pipe/nn, plate/nn, pony/nn, puppy/nn, purse/nn, rabbit/nn, ride/nn, ring/nn, room/nn, seat/nn, shirts/nn, shirt/nn, shower/nn, spec/nn, spot/nn, suit/nn, sweatshirt/nn, tub/nn, uniform/nn, walking/nn
:::

## Inside the theme clouds #2 {visibility="uncounted"}

::: {style="font-size: 0.5em;"}
-   **Theme.appeal:** appeal/nn, appointment/nn, choice/nn, custody/nn, decision/nn, demonstration/nn, demonstrator/nn, detention/nn, election/nn, felony/nn, jurisdiction/nn, law/nn, nomination/nn, order/nn, parole/nn, penalty/nn, punishment/nn, release/nn, right/nn, rule/nn, sentence/nn, trial/nn, verdict/nn

-   **Theme.power:** power/nn, ability/nn, activity/nn, advantage/nn, ambition/nn, attention/nn, balance/nn, chance/nn, command/nn, concession/nn, consistency/nn, control/nn, credibility/nn, dignity/nn, direction/nn, flexibility/nn, focus/nn, foothold/nn, freedom/nn, goal/nn, importance/nn, independence/nn, interest/nn, isolation/nn, leeway/nn, opportunity/nn, patronage/nn, peace/nn, policy/nn, potential/nn, power/nn, preference/nn, process/nn, preference/nn, push/nn, rein/nn, self-esteem/nn, skill/nn, strenght/nn, support/nn, talent/nn, thrust/nn, traction/nn, variance/nn

-   **Theme.drug:** drug/nn, ache/nn, aids/nn, awareness/nn, blood/nn, diet/nn, effect/nn, evaluation/nn, exercise/nn, exposure/nn, hdls/np, headache/nn, injection/nn, interaction/nn, medication/nn, medicine/nn, penicillin/nn, pill/nn, prescription/nn, rash/nn, relaxation/nn, simulation/nn, stroke/nn, test/nn, testing/nn, therapy/nn, transfusion/nn, workout/nn

-   **Theme.doubt:** doubt/nn, affection/nn, answer/nn, appreciation/nn, background/nn, experience/nn, feeling/nn, grief/nn, idea/nn, impression/nn, insight/nn, knowledge/nn, life/nn, motivation/nn, motive/nn, payback/nn, perspective/nn, question/nn, reason/nn, respect/nn, sense/nn, slant/nn, sympathy/nn, thought/nn, uplift/nn, view/nn
:::
